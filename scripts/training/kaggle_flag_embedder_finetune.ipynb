{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9abee93c-e79b-42af-aa2c-0433b78b5718",
    "_uuid": "c81e478e-1cb0-4a17-a60d-3770daf98893",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-07T11:26:16.632747Z",
     "iopub.status.busy": "2025-10-07T11:26:16.632475Z",
     "iopub.status.idle": "2025-10-07T11:26:20.537103Z",
     "shell.execute_reply": "2025-10-07T11:26:20.536341Z",
     "shell.execute_reply.started": "2025-10-07T11:26:16.632727Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -U FlagEmbedding[finetune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a78745e6-9cda-40e0-bc05-298c0f63627a",
    "_uuid": "5a6c29bf-635f-4397-bf08-f0aac597faaa",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-07T11:26:20.538812Z",
     "iopub.status.busy": "2025-10-07T11:26:20.538531Z",
     "iopub.status.idle": "2025-10-07T11:26:26.670227Z",
     "shell.execute_reply": "2025-10-07T11:26:26.669479Z",
     "shell.execute_reply.started": "2025-10-07T11:26:20.538791Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.3/flash_attn-2.7.3+cu12torch2.6cxx11abiFALSE-cp311-cp311-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85687843-9eeb-4c92-8795-cc9e5c042f92",
    "_uuid": "7fdd46e5-3a58-46ef-ba90-0acca94f0ee5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-07T12:46:42.010204Z",
     "iopub.status.busy": "2025-10-07T12:46:42.009873Z",
     "iopub.status.idle": "2025-10-07T12:46:42.605155Z",
     "shell.execute_reply": "2025-10-07T12:46:42.604259Z",
     "shell.execute_reply.started": "2025-10-07T12:46:42.010179Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/test_encoder_only_base_multilingual-e5-base/checkpoint-6945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "57e876b0-c02f-4d17-8e5a-91f233c45cc5",
    "_uuid": "e5e53aa3-8ab3-4d23-8297-4045dfb0b9b5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-07T16:05:37.640830Z",
     "iopub.status.busy": "2025-10-07T16:05:37.640421Z",
     "iopub.status.idle": "2025-10-07T16:05:37.646801Z",
     "shell.execute_reply": "2025-10-07T16:05:37.645681Z",
     "shell.execute_reply.started": "2025-10-07T16:05:37.640802Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bd65d1d4-100f-4156-8278-6bb3a99f74fc",
    "_uuid": "3a9a4595-ef23-4bf1-8f20-61a20c3d5526",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-07T12:04:26.019257Z",
     "iopub.status.busy": "2025-10-07T12:04:26.018428Z",
     "iopub.status.idle": "2025-10-07T12:04:26.025470Z",
     "shell.execute_reply": "2025-10-07T12:04:26.024900Z",
     "shell.execute_reply.started": "2025-10-07T12:04:26.019229Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds_stage = {\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 0\n",
    "    },\n",
    "    \n",
    "    \"fp16\": {\n",
    "        \"enabled\": \"auto\",\n",
    "        \"loss_scale\": 0,\n",
    "        \"loss_scale_window\": 1000,\n",
    "        \"initial_scale_power\": 12,\n",
    "        \"hysteresis\": 2,\n",
    "        \"min_loss_scale\": 1\n",
    "    },\n",
    "\n",
    "    \"bf16\": {\n",
    "        \"enabled\": \"auto\"\n",
    "    },\n",
    "\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"AdamW\",\n",
    "        \"params\": {\n",
    "            \"lr\": \"auto\",\n",
    "            \"betas\": \"auto\",\n",
    "            \"eps\": \"auto\",\n",
    "            \"weight_decay\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"scheduler\": {\n",
    "        \"type\": \"WarmupDecayLR\",\n",
    "        \"params\": {\n",
    "            \"warmup_min_lr\": \"auto\",\n",
    "            \"warmup_max_lr\": \"auto\",\n",
    "            \"warmup_num_steps\": \"auto\",\n",
    "            \"total_num_steps\": \"auto\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"gradient_accumulation_steps\": \"auto\",\n",
    "    \"gradient_clipping\": \"auto\",\n",
    "    \"steps_per_print\": 100,\n",
    "    \"train_batch_size\": \"auto\",\n",
    "    \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "    \"wall_clock_breakdown\": False\n",
    "}\n",
    "\n",
    "# dump to file\n",
    "with open('/kaggle/working/ds_stage0.json', 'w') as file:\n",
    "    json.dump(ds_stage, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a740b7cf-7044-4a9f-92d4-8461831bfb0b",
    "_uuid": "29e4fb85-6513-4474-884d-0eb2481b8055",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-07T12:04:31.492393Z",
     "iopub.status.busy": "2025-10-07T12:04:31.492127Z",
     "iopub.status.idle": "2025-10-07T12:04:31.496074Z",
     "shell.execute_reply": "2025-10-07T12:04:31.495275Z",
     "shell.execute_reply.started": "2025-10-07T12:04:31.492375Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "04c0951b-9718-4084-8c3f-068af2b2d024",
    "_uuid": "a467c984-ac25-49ac-b8e8-fc60ad4794ad",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!torchrun --nproc_per_node 2 \\\n",
    "\t-m FlagEmbedding.finetune.embedder.encoder_only.base \\\n",
    "\t--model_name_or_path intfloat/multilingual-e5-base \\\n",
    "    --cache_dir /kaggle/working/cache/model \\\n",
    "    --train_data /kaggle/input/course-esco-skill-retrieval/train_dataset.jsonl \\\n",
    "    --cache_path /kaggle/working/cache/data \\\n",
    "    --train_group_size 8 \\\n",
    "    --query_max_len 512 \\\n",
    "    --passage_max_len 512 \\\n",
    "    --pad_to_multiple_of 8 \\\n",
    "    --query_instruction_for_retrieval 'query: ' \\\n",
    "    --query_instruction_format '{}{}' \\\n",
    "    --passage_instruction_for_retrieval 'passage: ' \\\n",
    "    --passage_instruction_format '{}{}' \\\n",
    "    --knowledge_distillation False \\\n",
    "\t--output_dir ./test_encoder_only_base_multilingual-e5-base \\\n",
    "    --overwrite_output_dir \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --fp16 \\\n",
    "    --num_train_epochs 5 \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --dataloader_drop_last True \\\n",
    "    --warmup_ratio 0.2 \\\n",
    "    --gradient_checkpointing \\\n",
    "    --deepspeed /kaggle/working/ds_stage0.json \\\n",
    "    --logging_steps 50 \\\n",
    "    --save_steps 2000 \\\n",
    "    --save_total_limit 1 \\\n",
    "    --negatives_cross_device \\\n",
    "    --temperature 0.02 \\\n",
    "    --sentence_pooling_method cls \\\n",
    "    --normalize_embeddings True \\\n",
    "    --kd_loss_type kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T13:36:19.054978Z",
     "iopub.status.busy": "2025-10-07T13:36:19.054627Z",
     "iopub.status.idle": "2025-10-07T13:36:21.017885Z",
     "shell.execute_reply": "2025-10-07T13:36:21.017150Z",
     "shell.execute_reply.started": "2025-10-07T13:36:19.054949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Load trained model (FlagEmbedding output directory)\n",
    "raw_output_dir = Path('/kaggle/working/test_encoder_only_base_multilingual-e5-base')\n",
    "print('Raw output dir exists:', raw_output_dir.exists())\n",
    "\n",
    "# Load the model using SentenceTransformer (this works for many HuggingFace-style layouts)\n",
    "model = SentenceTransformer(str(raw_output_dir))\n",
    "print('Loaded model OK. Saving a clean deployable copy...')\n",
    "\n",
    "# Create a clean deploy folder and save using SentenceTransformer.save()\n",
    "deploy_dir = Path(str(raw_output_dir) + '_deployed')\n",
    "if deploy_dir.exists():\n",
    "    print('Deploy dir already exists. Removing and recreating to ensure clean layout.')\n",
    "    shutil.rmtree(deploy_dir)\n",
    "\n",
    "# Save a clean SentenceTransformers-style model suitable for deployment\n",
    "model.save(str(deploy_dir))\n",
    "print('Saved deployed model to:', deploy_dir)\n",
    "\n",
    "# Optionally remove intermediate checkpoint directories in raw output to save space\n",
    "for cp in raw_output_dir.glob('checkpoint-*'):\n",
    "    try:\n",
    "        print('Removing checkpoint:', cp.name)\n",
    "        shutil.rmtree(cp)\n",
    "    except Exception as e:\n",
    "        print('Failed to remove checkpoint', cp, e)\n",
    "\n",
    "# Update a variable used by packaging cell\n",
    "deployed_model_dir = deploy_dir\n",
    "print('Deployed model directory set to:', deployed_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T13:36:24.588843Z",
     "iopub.status.busy": "2025-10-07T13:36:24.588533Z",
     "iopub.status.idle": "2025-10-07T13:36:25.468754Z",
     "shell.execute_reply": "2025-10-07T13:36:25.468002Z",
     "shell.execute_reply.started": "2025-10-07T13:36:24.588821Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# üß™ Comprehensive Model Testing and Analysis\n",
    "\n",
    "# üìÇ Load training data\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL data with progress info.\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    print(f\"üìÇ Loading: {file_path.name}\")\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                try:\n",
    "                    sample = json.loads(line)\n",
    "                    data.append(sample)\n",
    "                    \n",
    "                    # Show examples\n",
    "                    if i < 3:  # Show first 3 examples\n",
    "                        query_len = len(sample.get('query', ''))\n",
    "                        pos_count = len(sample.get('pos', []))\n",
    "                        neg_count = len(sample.get('neg', []))\n",
    "                        print(f\"   Example {i+1}: {query_len} chars, {pos_count} pos, {neg_count} neg\")\n",
    "                        \n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(data)} samples\")\n",
    "    return data\n",
    "\n",
    "# Load evaluation data if available\n",
    "eval_data = []\n",
    "eval_data = load_jsonl(Path(\"/kaggle/input/course-esco-skill-retrieval/eval_dataset.jsonl\"))\n",
    "print(f\"‚úÖ Loaded {len(eval_data)} evaluation samples\")\n",
    "\n",
    "if eval_data and len(eval_data) > 0:\n",
    "    print(\"üß™ Comprehensive Model Testing & Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test with multiple samples for robust evaluation\n",
    "    test_samples = eval_data[:10]  # Test with first 5 samples\n",
    "    \n",
    "    all_pos_similarities = []\n",
    "    all_neg_similarities = []\n",
    "    \n",
    "    for idx, test_sample in enumerate(test_samples):\n",
    "        test_query = test_sample.get('query', '').strip()\n",
    "        pos_test_skills = [skill.strip() for skill in test_sample.get('pos', []) if skill.strip()][:3]\n",
    "        neg_test_skills = [skill.strip() for skill in test_sample.get('neg', []) if skill.strip()][:3]\n",
    "        \n",
    "        # Validate sample has required data\n",
    "        if not test_query:\n",
    "            print(f\"\\n‚ö†Ô∏è Test Sample {idx+1}: Empty query, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        if not pos_test_skills:\n",
    "            print(f\"\\n‚ö†Ô∏è Test Sample {idx+1}: No valid positive skills, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        if not neg_test_skills:\n",
    "            print(f\"\\n‚ö†Ô∏è Test Sample {idx+1}: No valid negative skills, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nüìù Test Sample {idx+1}:\")\n",
    "        print(f\"   Query: {test_query[:100]}{'...' if len(test_query) > 100 else ''}\")\n",
    "        print(f\"   Positive skills: {len(pos_test_skills)}, Negative skills: {len(neg_test_skills)}\")\n",
    "        \n",
    "        try:\n",
    "            # Encode with E5 prefixes\n",
    "            query_text = f\"query: {test_query}\"\n",
    "            pos_skill_texts = [f\"passage: {skill}\" for skill in pos_test_skills]\n",
    "            neg_skill_texts = [f\"passage: {skill}\" for skill in neg_test_skills]\n",
    "            \n",
    "            # Encode and validate embeddings\n",
    "            query_embedding = model.encode([query_text])\n",
    "            pos_skill_embeddings = model.encode(pos_skill_texts)\n",
    "            neg_skill_embeddings = model.encode(neg_skill_texts)\n",
    "            \n",
    "            # Validate embedding shapes\n",
    "            if query_embedding.shape[0] == 0:\n",
    "                print(f\"   ‚ùå Empty query embedding, skipping...\")\n",
    "                continue\n",
    "            if pos_skill_embeddings.shape[0] == 0:\n",
    "                print(f\"   ‚ùå Empty positive skill embeddings, skipping...\")\n",
    "                continue\n",
    "            if neg_skill_embeddings.shape[0] == 0:\n",
    "                print(f\"   ‚ùå Empty negative skill embeddings, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"   üìê Embedding shapes: query{query_embedding.shape}, pos{pos_skill_embeddings.shape}, neg{neg_skill_embeddings.shape}\")\n",
    "            \n",
    "            # Compute similarities\n",
    "            pos_similarities = model.similarity(query_embedding, pos_skill_embeddings)[0]\n",
    "            neg_similarities = model.similarity(query_embedding, neg_skill_embeddings)[0]\n",
    "            \n",
    "            # Store for overall analysis\n",
    "            all_pos_similarities.extend(pos_similarities.tolist())\n",
    "            all_neg_similarities.extend(neg_similarities.tolist())\n",
    "            \n",
    "            print(f\"   üìä Positive skills (should be high similarity):\")\n",
    "            for i, (skill, score) in enumerate(zip(pos_test_skills, pos_similarities)):\n",
    "                print(f\"      {score:.4f} - {skill[:80]}{'...' if len(skill) > 80 else ''}\")\n",
    "            \n",
    "            print(f\"   üìä Negative skills (should be low similarity):\")\n",
    "            for i, (skill, score) in enumerate(zip(neg_test_skills, neg_similarities)):\n",
    "                print(f\"      {score:.4f} - {skill[:80]}{'...' if len(skill) > 80 else ''}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error processing sample {idx+1}: {str(e)}\")\n",
    "            print(f\"   üîç Query length: {len(test_query)}\")\n",
    "            print(f\"   üîç Pos skills: {len(pos_test_skills)} items\")\n",
    "            print(f\"   üîç Neg skills: {len(neg_test_skills)} items\")\n",
    "            continue\n",
    "    \n",
    "    # Overall performance analysis\n",
    "    print(f\"\\nüìà OVERALL PERFORMANCE ANALYSIS:\")\n",
    "    print(f\"=\" * 40)\n",
    "    \n",
    "    if not all_pos_similarities or not all_neg_similarities:\n",
    "        print(\"‚ùå No valid similarities computed!\")\n",
    "        print(f\"   Positive similarities: {len(all_pos_similarities)}\")\n",
    "        print(f\"   Negative similarities: {len(all_neg_similarities)}\")\n",
    "        print(\"üí° This suggests:\")\n",
    "        print(\"   - Training data may have empty or invalid entries\")\n",
    "        print(\"   - Model encoding may be failing\")\n",
    "        print(\"   - Check data format and model loading\")\n",
    "    else:\n",
    "        import numpy as np\n",
    "        \n",
    "        pos_mean = np.mean(all_pos_similarities)\n",
    "        pos_std = np.std(all_pos_similarities)\n",
    "        neg_mean = np.mean(all_neg_similarities)\n",
    "        neg_std = np.std(all_neg_similarities)\n",
    "        \n",
    "        separation = pos_mean - neg_mean\n",
    "        \n",
    "        print(f\"‚úÖ Positive similarities: {pos_mean:.4f} ¬± {pos_std:.4f}\")\n",
    "        print(f\"‚ùå Negative similarities: {neg_mean:.4f} ¬± {neg_std:.4f}\")\n",
    "        print(f\"üìè Separation (higher is better): {separation:.4f}\")\n",
    "        \n",
    "        # Quality assessment\n",
    "        if separation > 0.2:\n",
    "            quality = \"üåü Excellent\"\n",
    "        elif separation > 0.1:\n",
    "            quality = \"‚úÖ Good\"\n",
    "        elif separation > 0.05:\n",
    "            quality = \"‚ö†Ô∏è Fair\"\n",
    "        else:\n",
    "            quality = \"‚ùå Poor\"\n",
    "        \n",
    "        print(f\"üéØ Model Quality: {quality}\")\n",
    "        \n",
    "        # Ranking test\n",
    "        print(f\"\\nüèÜ RANKING TEST:\")\n",
    "        print(f\"Testing if positive skills rank higher than negative skills...\")\n",
    "        \n",
    "        correct_rankings = 0\n",
    "        total_comparisons = 0\n",
    "        \n",
    "        for i in range(len(all_pos_similarities)):\n",
    "            for j in range(len(all_neg_similarities)):\n",
    "                if all_pos_similarities[i] > all_neg_similarities[j]:\n",
    "                    correct_rankings += 1\n",
    "                total_comparisons += 1\n",
    "        \n",
    "        ranking_accuracy = correct_rankings / total_comparisons if total_comparisons > 0 else 0\n",
    "        print(f\"üéØ Ranking Accuracy: {ranking_accuracy:.3f} ({correct_rankings}/{total_comparisons})\")\n",
    "        \n",
    "        if ranking_accuracy > 0.8:\n",
    "            ranking_quality = \"üåü Excellent\"\n",
    "        elif ranking_accuracy > 0.7:\n",
    "            ranking_quality = \"‚úÖ Good\"\n",
    "        elif ranking_accuracy > 0.6:\n",
    "            ranking_quality = \"‚ö†Ô∏è Fair\"\n",
    "        else:\n",
    "            ranking_quality = \"‚ùå Poor\"\n",
    "        \n",
    "        print(f\"üèÜ Ranking Quality: {ranking_quality}\")\n",
    "        \n",
    "        # Recommendations\n",
    "        print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "        if separation < 0.1:\n",
    "            print(\"   üìà Consider increasing training epochs or learning rate\")\n",
    "            print(\"   üéØ Add more negative examples or harder negatives\")\n",
    "        if ranking_accuracy < 0.7:\n",
    "            print(\"   üîÑ Try different loss functions (CoSENT, Triplet)\")\n",
    "            print(\"   üìä Increase batch size for better negative sampling\")\n",
    "        if pos_std > 0.3:\n",
    "            print(\"   üìè High variance in positive similarities - check data quality\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No test data available\")\n",
    "    print(\"üí° Suggestions:\")\n",
    "    print(\"   - Check if training data was loaded properly\")\n",
    "    print(\"   - Verify data format: should have 'query', 'pos', 'neg' fields\")\n",
    "    print(\"   - Ensure positive and negative skills are not empty lists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:05:44.024736Z",
     "iopub.status.busy": "2025-10-07T16:05:44.024349Z",
     "iopub.status.idle": "2025-10-07T16:12:42.743541Z",
     "shell.execute_reply": "2025-10-07T16:12:42.741702Z",
     "shell.execute_reply.started": "2025-10-07T16:05:44.024706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import shutil\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# üì¶ Create downloadable model package (robust)\n",
    "# Use the clean deployed model directory if available\n",
    "output_dir = Path(globals().get('deployed_model_dir', Path('/kaggle/working/test_encoder_only_base_multilingual-e5-base_deployed')))\n",
    "required_files = [\n",
    "    'config.json',\n",
    "    'tokenizer.json',\n",
    "    'tokenizer_config.json',\n",
    "    'special_tokens_map.json',\n",
    "    'sentencepiece.bpe.model',\n",
    "    'model.safetensors',\n",
    "    'pytorch_model.bin',\n",
    "    'modules.json',\n",
    "    'config_sentence_transformers.json',\n",
    "    'sentence_bert_config.json'\n",
    "]\n",
    "\n",
    "if output_dir.exists():\n",
    "    print(\"üì¶ Creating download package (including required files from deployed model)...\")\n",
    "\n",
    "    # Create zip file\n",
    "    filename = f\"finetuned_esco_model.zip\"\n",
    "    zip_filename = Path(f\"/kaggle/working/{filename}\")\n",
    "\n",
    "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Walk output directory and selectively add files\n",
    "        for root, dirs, files in os.walk(output_dir):\n",
    "            # Exclude checkpoint directories and logs\n",
    "            dirs[:] = [d for d in dirs if not d.startswith('checkpoint-') and d != 'logs' and d != 'runs']\n",
    "\n",
    "            for file in files:\n",
    "                file_path = Path(root) / file\n",
    "                rel = file_path.relative_to(output_dir)\n",
    "\n",
    "                # Always include required files if present\n",
    "                if file in required_files:\n",
    "                    zipf.write(file_path, rel)\n",
    "                    print(f\"   + {rel} (required)\")\n",
    "                    continue\n",
    "\n",
    "                # Also include model files under common dirs (e.g., pytorch_model-*.bin, *.safetensors)\n",
    "                if file.endswith('.safetensors') or file.startswith('pytorch_model') or file.endswith('.bin') or file.endswith('.json'):\n",
    "                    zipf.write(file_path, rel)\n",
    "                    print(f\"   + {rel}\")\n",
    "                    continue\n",
    "\n",
    "                # Include tokenizer files and modules\n",
    "                if 'tokenizer' in file.lower() or 'vocab' in file.lower() or 'module' in file.lower():\n",
    "                    zipf.write(file_path, rel)\n",
    "                    print(f\"   + {rel}\")\n",
    "                    continue\n",
    "\n",
    "        # Add README to zip\n",
    "        usage_info = f\"\"\"# Fine-tuned ESCO Skill Retrieval Model\n",
    "\n",
    "This archive contains the files required to load the model with SentenceTransformers/HuggingFace.\n",
    "\n",
    "Required files included (when available): {', '.join([f for f in required_files])}\n",
    "\n",
    "Loading example:\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('path/to/extracted/model')\n",
    "```\n",
    "\n",
    "Note: If you see errors about missing tokenizer or config, ensure the extracted folder contains `config.json` and tokenizer files.\n",
    "\"\"\"\n",
    "        zipf.writestr('README.md', usage_info)\n",
    "\n",
    "    # Check file size\n",
    "    file_size = zip_filename.stat().st_size / 1e6  # MB\n",
    "\n",
    "    print(f\"\\n‚úÖ Download package created: {zip_filename}\")\n",
    "    print(f\"üìä Size: {file_size:.1f} MB\")\n",
    "\n",
    "    # --- Verification: extract to temp and try to load with SentenceTransformer\n",
    "    print('\\nüîé Verifying archive by extracting and loading model...')\n",
    "    tmpdir = Path(tempfile.mkdtemp())\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_filename, 'r') as zipf:\n",
    "            zipf.extractall(tmpdir)\n",
    "\n",
    "        # Attempt to load\n",
    "        try:\n",
    "            test_model = SentenceTransformer(str(tmpdir))\n",
    "            print('‚úÖ Verification load successful: SentenceTransformer can load the extracted archive')\n",
    "        except Exception as e:\n",
    "            print('‚ùå Verification load failed: ', e)\n",
    "            print('Contents extracted to:', tmpdir)\n",
    "            print('List of extracted files:')\n",
    "            for p in tmpdir.rglob('*'):\n",
    "                print('  ', p.relative_to(tmpdir))\n",
    "            raise\n",
    "    finally:\n",
    "        # Clean up temporary extraction directory\n",
    "        try:\n",
    "            shutil.rmtree(tmpdir)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No deployed model found to package - run the cell that creates 'deployed_model_dir' first\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T16:24:41.158899Z",
     "iopub.status.busy": "2025-10-07T16:24:41.157397Z",
     "iopub.status.idle": "2025-10-07T16:24:41.169263Z",
     "shell.execute_reply": "2025-10-07T16:24:41.167894Z",
     "shell.execute_reply.started": "2025-10-07T16:24:41.158840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create download link\n",
    "from IPython.display import FileLink\n",
    "FileLink(filename)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8397944,
     "sourceId": 13261402,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
